{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test set:\n",
    "df = pd.read_parquet('/home/ndo/vardict_ML/train_test_shuffle_data/test_dataset.parquet')\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X_test = df.drop(columns=['labels'])  # Features\n",
    "y_test = df['labels']  # Target labels\n",
    "\n",
    "# Load train set:\n",
    "df = pd.read_parquet('/home/ndo/vardict_ML/train_test_shuffle_data/train_dataset.parquet')\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X_train = df.drop(columns=['labels'])  # Features\n",
    "y_train = df['labels']  # Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler (without fitting again)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print(len(X_train_scaled[0]))\n",
    "# Convert back to DataFrame for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset saved to 'train_scaled_dataset.parquet'\n",
      "Test dataset saved to 'test_scaled_dataset.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Combine X_train and y_train into a single DataFrame\n",
    "train_scaled_data = X_train_scaled_df.copy()  # Make a copy of X_train to avoid modifying the original\n",
    "train_scaled_data['labels'] = y_train  # Add y_train as a column named 'labels' in the DataFrame\n",
    "\n",
    "# Step 2: Write the DataFrame to a Parquet file\n",
    "train_scaled_data.to_parquet('/home/ndo/vardict_ML/train_test_shuffle_data/train_scaled_dataset.parquet')\n",
    "\n",
    "print(\"Train dataset saved to 'train_scaled_dataset.parquet'\")\n",
    "\n",
    "# Step 1: Combine X_test and y_test into a single DataFrame\n",
    "test_scaled_data = X_test_scaled_df.copy()  # Make a copy of X_test to avoid modifying the original\n",
    "test_scaled_data['labels'] = y_test  # Add y_test as a column named 'target' in the DataFrame\n",
    "\n",
    "# Step 2: Write the DataFrame to a Parquet file\n",
    "test_scaled_data.to_parquet('/home/ndo/vardict_ML/train_test_shuffle_data/test_scaled_dataset.parquet')\n",
    "\n",
    "print(\"Test dataset saved to 'test_scaled_dataset.parquet'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled_data.dropna(subset=['labels'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DP           0\n",
       "VD           0\n",
       "AF           0\n",
       "PMEAN        0\n",
       "PSTD         0\n",
       "QUAL         0\n",
       "QSTD         0\n",
       "SBF          0\n",
       "ODDRATIO     0\n",
       "MQ           0\n",
       "SN           0\n",
       "HIAF         0\n",
       "ADJAF        0\n",
       "SHIFT3       0\n",
       "MSI          0\n",
       "MSILEN       0\n",
       "NM           0\n",
       "HICNT        0\n",
       "HICOV        0\n",
       "DUPRATE      0\n",
       "SPLITREAD    0\n",
       "SPANPAIR     0\n",
       "labels       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset saved to 'test_scaled_dataset.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Combine X_test and y_test into a single DataFrame\n",
    "test_scaled_data = X_test_scaled_df.copy()  # Make a copy of X_test to avoid modifying the original\n",
    "test_scaled_data['labels'] = y_test  # Add y_test as a column named 'target' in the DataFrame\n",
    "\n",
    "# Step 2: Write the DataFrame to a Parquet file\n",
    "test_scaled_data.to_parquet('/home/ndo/vardict_ML/train_test_shuffle_data/test_scaled__SRR106_dataset.parquet')\n",
    "\n",
    "print(\"Test dataset saved to 'test_scaled_dataset.parquet'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
